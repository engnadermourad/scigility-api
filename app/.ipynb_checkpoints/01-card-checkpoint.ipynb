{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fadc0fe5-a07e-45d8-8180-5113269f30fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------+\n",
      "|card_id|disp_id|   type|    issued|\n",
      "+-------+-------+-------+----------+\n",
      "|      1|      9|   gold|1998-10-16|\n",
      "|      2|     19|classic|1998-03-13|\n",
      "|      3|     41|   gold|1995-09-03|\n",
      "|      4|     42|classic|1998-11-26|\n",
      "|      5|     51| junior|1995-04-24|\n",
      "|      7|     56|classic|1998-06-11|\n",
      "|      8|     60| junior|1998-05-20|\n",
      "|      9|     76|classic|1997-10-25|\n",
      "|     10|     77|classic|1996-12-07|\n",
      "|     11|     79|   gold|1997-10-25|\n",
      "|     12|     83| junior|1996-09-11|\n",
      "|     13|     87|classic|1994-06-29|\n",
      "|     14|    112|classic|1996-02-17|\n",
      "|     15|    114|classic|1995-03-05|\n",
      "|     16|    116|classic|1998-06-23|\n",
      "|     17|    127|classic|1998-06-07|\n",
      "|     18|    128|classic|1995-08-25|\n",
      "|     19|    130|classic|1997-09-09|\n",
      "|     20|    131|classic|1998-12-02|\n",
      "|     21|    132|classic|1998-02-26|\n",
      "+-------+-------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get AWS credentials from environment variables\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CSV to Parquet spark master 3\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", aws_access_key_id) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", aws_secret_access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\") \\\n",
    "    .master(\"spark://spark-master-3:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define schema for the CSV file\n",
    "schema = StructType([\n",
    "    StructField(\"card_id\", IntegerType(), True),\n",
    "    StructField(\"disp_id\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"issued\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Read the CSV file from the S3 bucket, use first row as header\n",
    "df = spark.read \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"s3a://nmourmx-scigility/Bronze/card/card.csv\")  # Path to card.csv inside the card folder\n",
    "\n",
    "# Cache the DataFrame to improve performance\n",
    "df = df.cache()\n",
    "\n",
    "# Show the first few rows to verify the data\n",
    "df.show(20)\n",
    "\n",
    "# Convert the 'issued' column to a proper date type\n",
    "df = df.withColumn(\"issued\", df[\"issued\"].cast(DateType()))\n",
    "\n",
    "# Persist the DataFrame with MEMORY_AND_DISK storage level (useful for large data)\n",
    "df = df.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "# Save the DataFrame to S3 in the Silver folder as Parquet\n",
    "df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"s3a://nmourmx-scigility/Silver/card_parquet/\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06a3a0-dbce-48de-8f69-d5839885a673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
